#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•Isaac Simæ•°æ®é›†æ˜¯å¦ç¬¦åˆPoETè¦æ±‚
"""

import sys
import os
sys.path.append('/data/gplong/force_map_project/w-poet/poet')

import torch
import json
from pathlib import Path
from data_utils.pose_dataset import build
import argparse

class Args:
    """æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°"""
    def __init__(self):
        # ä½¿ç”¨åŸå§‹æ•°æ®é›†è·¯å¾„ä½œä¸ºæ ¹ç›®å½•ï¼Œæ ‡æ³¨æ–‡ä»¶åœ¨å­ç›®å½•ä¸­
        self.dataset_path = '/data/gplong/force_map_project/isaac_sim_poet_dataset_new'
        self.synt_background = None
        self.rgb_augmentation = False
        self.grayscale = False
        self.bbox_mode = 'gt'
        self.jitter_probability = 0.5
        self.cache_mode = False

def test_dataset_loading():
    """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("å¼€å§‹æµ‹è¯•Isaac Simæ•°æ®é›†...")
    
    args = Args()
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨
    dataset_path = Path(args.dataset_path)
    if not dataset_path.exists():
        print(f"é”™è¯¯ï¼šæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ {dataset_path}")
        return False
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    train_json = dataset_path / 'annotations' / 'train.json'
    val_json = dataset_path / 'annotations' / 'val.json'
    classes_json = dataset_path / 'annotations' / 'classes.json'
    
    for file_path in [train_json, val_json, classes_json]:
        if not file_path.exists():
            print(f"é”™è¯¯ï¼šç¼ºå°‘æ–‡ä»¶ {file_path}")
            return False
        print(f"âœ“ æ‰¾åˆ°æ–‡ä»¶: {file_path}")
    
    try:
        # åŠ è½½è®­ç»ƒæ•°æ®é›†
        print("\nåŠ è½½è®­ç»ƒæ•°æ®é›†...")
        train_dataset = build('train', args)
        print(f"âœ“ è®­ç»ƒæ•°æ®é›†åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(train_dataset)} ä¸ªæ ·æœ¬")
        
        # åŠ è½½éªŒè¯æ•°æ®é›†
        print("\nåŠ è½½éªŒè¯æ•°æ®é›†...")
        val_dataset = build('val', args)
        print(f"âœ“ éªŒè¯æ•°æ®é›†åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(val_dataset)} ä¸ªæ ·æœ¬")
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªæ ·æœ¬
        print("\næµ‹è¯•ç¬¬ä¸€ä¸ªè®­ç»ƒæ ·æœ¬...")
        img, target = train_dataset[0]
        
        print(f"å›¾åƒå½¢çŠ¶: {img.shape}")
        print(f"å›¾åƒç±»å‹: {type(img)}")
        
        # æ£€æŸ¥targetå­—æ®µ
        required_fields = ['boxes', 'labels', 'image_id']
        optional_fields = ['relative_position', 'relative_quaternions', 'relative_rotation', 'intrinsics']
        
        print("\næ£€æŸ¥targetå­—æ®µ:")
        for field in required_fields:
            if field in target:
                print(f"âœ“ {field}: {target[field].shape if hasattr(target[field], 'shape') else type(target[field])}")
            else:
                print(f"âœ— ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        for field in optional_fields:
            if field in target:
                print(f"âœ“ {field}: {target[field].shape if hasattr(target[field], 'shape') else type(target[field])}")
            else:
                print(f"- å¯é€‰å­—æ®µæœªæ‰¾åˆ°: {field}")
        
        # æ£€æŸ¥å§¿æ€æ•°æ®
        if 'relative_position' in target and 'relative_rotation' in target:
            print(f"\nå§¿æ€æ•°æ®æ£€æŸ¥:")
            print(f"ç›¸å¯¹ä½ç½®: {target['relative_position']}")
            print(f"ç›¸å¯¹æ—‹è½¬çŸ©é˜µå½¢çŠ¶: {target['relative_rotation'].shape}")
            print(f"è¾¹ç•Œæ¡†: {target['boxes']}")
            print(f"ç±»åˆ«æ ‡ç­¾: {target['labels']}")
        
        print("\nâœ“ æ•°æ®é›†æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"é”™è¯¯ï¼šæ•°æ®é›†åŠ è½½å¤±è´¥ - {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def check_data_statistics():
    """æ£€æŸ¥æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    print("\n=== æ•°æ®ç»Ÿè®¡ä¿¡æ¯ ===")
    
    # åŠ è½½ç±»åˆ«ä¿¡æ¯
    classes_file = '/data/gplong/force_map_project/isaac_sim_poet_dataset_new/annotations/classes.json'
    with open(classes_file, 'r') as f:
        classes = json.load(f)
    
    print(f"ç±»åˆ«æ•°é‡: {len(classes)}")
    print("ç±»åˆ«åˆ—è¡¨:")
    for class_id, class_name in classes.items():
        print(f"  {class_id}: {class_name}")
    
    # åŠ è½½è®­ç»ƒæ ‡æ³¨ç»Ÿè®¡
    train_file = '/data/gplong/force_map_project/isaac_sim_poet_dataset_new/annotations/train.json'
    with open(train_file, 'r') as f:
        train_data = json.load(f)
    
    print(f"\nè®­ç»ƒé›†å›¾åƒæ•°é‡: {len(train_data['images'])}")
    print(f"è®­ç»ƒé›†æ ‡æ³¨æ•°é‡: {len(train_data['annotations'])}")
    
    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ ‡æ³¨æ•°é‡
    category_counts = {}
    for ann in train_data['annotations']:
        cat_id = ann['category_id']
        category_counts[cat_id] = category_counts.get(cat_id, 0) + 1
    
    print("\nå„ç±»åˆ«æ ‡æ³¨æ•°é‡:")
    for cat_id, count in sorted(category_counts.items()):
        class_name = classes.get(str(cat_id), f"unknown_{cat_id}")
        print(f"  {class_name}: {count}")

if __name__ == '__main__':
    print("Isaac Simæ•°æ®é›†PoETå…¼å®¹æ€§æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ•°æ®é›†åŠ è½½
    success = test_dataset_loading()
    
    if success:
        # æ£€æŸ¥æ•°æ®ç»Ÿè®¡
        check_data_statistics()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®é›†ç¬¦åˆPoETè¦æ±‚ã€‚")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼æ•°æ®é›†ä¸ç¬¦åˆPoETè¦æ±‚ã€‚")
        sys.exit(1)